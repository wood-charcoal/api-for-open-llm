PORT=6006

# model related
MODEL_NAME=deepseek-ai
MODEL_PATH=/root/autodl-fs/modelscope/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
CONTEXT_LEN=
LOAD_IN_8BIT=false
LOAD_IN_4BIT=false

CONTEXT_LEN=
PROMPT_NAME=deepseek

# vllm setting
TRUST_REMOTE_CODE=
TOKENIZE_MODE=auto
TENSOR_PARALLEL_SIZE=1
GPU_MEMORY_UTILIZATION=0.95
MAX_NUM_BATCHED_TOKENS=256
MAX_NUM_SEQS=128
QUANTIZATION_METHOD=
ENFORCE_EAGER=
MAX_SEQ_LEN_TO_CAPTURE=
MAX_LORAS=
MAX_LORA_RANK=
LORA_EXTRA_VOCAB_SIZE=
LORA_DTYPE=
MAX_CPU_LORAS=
LORA_MODULES=
DISABLE_CUSTOM_ALL_REDUCE=
VLLM_DISABLE_LOG_STATS=
DISTRIBUTED_EXECUTOR_BACKEND=

# rag related
EMBEDDING_NAME=
RERANK_NAME=

# device related
# "auto", "cuda:0", "cuda:1", ...
DEVICE_MAP=auto
GPUS=
NUM_GPUs=1
DTYPE=half


# api related
API_PREFIX=/v1
API_KEYS=1234

USE_STREAMER_V2=false
ENGINE=vllm

TASKS=llm
# TASKS=llm,rag